{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==============                                                          ]  20%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1, 10)             5000      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 8,406\n",
      "Trainable params: 8,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "Episode: 1\n",
      "+---------+\n",
      "|\u001B[43mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "**********************************\n",
      "reward is :\n",
      "-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==============                                                          ]  20%\r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from drawnow import drawnow\n",
    "from IPython.display import clear_output\n",
    "from collections import deque\n",
    "import progressbar\n",
    "\n",
    "import gym\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def makeFig():\n",
    "    plt.scatter(xList,yList) # I think you meant this\n",
    "plt.ion() # enable interactivity\n",
    "fig=plt.figure() # make a figure\n",
    "\n",
    "xList=list()\n",
    "yList=list()\n",
    "#make environment\n",
    "enviroment = gym.make(\"Taxi-v3\").env\n",
    "#enviroment.render()\n",
    "#print('Number of states: {}'.format(enviroment.observation_space.n))\n",
    "#print('Number of actions: {}'.format(enviroment.action_space.n))\n",
    "\n",
    "#agent class\n",
    "class Agent:\n",
    "    def __init__(self, enviroment, optimizer):\n",
    "\n",
    "        # Initialize atributes\n",
    "        self._state_size = enviroment.observation_space.n\n",
    "        self._action_size = enviroment.action_space.n\n",
    "        self._optimizer = optimizer\n",
    "\n",
    "        self.expirience_replay = deque(maxlen=2000)#random sample\n",
    "\n",
    "        # Initialize discount and exploration rate/ hyper parameters\n",
    "        self.gamma = 0.7 #discounting rate\n",
    "        self.epsilon = 0.2\n",
    "\n",
    "        # Build networks\n",
    "        self.q_network = self._build_compile_model()\n",
    "        self.target_network = self._build_compile_model()\n",
    "        self.alighn_target_model()\n",
    "\n",
    "    def store(self, state, action, reward, next_state, terminated):\n",
    "        self.expirience_replay.append((state, action, reward, next_state, terminated))\n",
    "\n",
    "    def _build_compile_model(self):#core\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(self._state_size, 10, input_length=1))\n",
    "        model.add(Reshape((10,)))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(self._action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=self._optimizer)\n",
    "        return model\n",
    "\n",
    "    def alighn_target_model(self):#set parameter to tar_get network\n",
    "        self.target_network.set_weights(self.q_network.get_weights())\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return enviroment.action_space.sample()\n",
    "        q_values = self.q_network.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def retrain(self, batch_size):#retrain from experience memory\n",
    "        minibatch = random.sample(self.expirience_replay, batch_size)\n",
    "\n",
    "        for state, action, reward, next_state, terminated in minibatch:\n",
    "\n",
    "            target = self.q_network.predict(state)\n",
    "\n",
    "            if terminated:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                t = self.target_network.predict(next_state)\n",
    "                target[0][action] = reward + self.gamma * np.amax(t)\n",
    "\n",
    "            self.q_network.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=0.05)\n",
    "agent = Agent(enviroment, optimizer)\n",
    "\n",
    "batch_size = 32\n",
    "num_of_episodes = 10\n",
    "timesteps_per_episode = 100\n",
    "agent.q_network.summary()\n",
    "for e in range(0, num_of_episodes):\n",
    "    # Reset the enviroment\n",
    "    state = enviroment.reset()\n",
    "    state = np.reshape(state, [1, 1])\n",
    "\n",
    "    # Initialize variables\n",
    "    reward = 0\n",
    "    terminated = False\n",
    "\n",
    "\n",
    "    bar = progressbar.ProgressBar(maxval=timesteps_per_episode/10, widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    for timestep in range(timesteps_per_episode):\n",
    "        # Run Action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Take action\n",
    "        next_state, reward, terminated, info = enviroment.step(action)\n",
    "        next_state = np.reshape(next_state, [1, 1])\n",
    "        agent.store(state, action, reward, next_state, terminated)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if terminated:\n",
    "            agent.alighn_target_model()\n",
    "            break\n",
    "\n",
    "        if len(agent.expirience_replay) > batch_size:\n",
    "            agent.retrain(batch_size)\n",
    "\n",
    "        if timestep%10 == 0:\n",
    "            bar.update(timestep/10 + 1)\n",
    "\n",
    "    bar.finish()\n",
    "    print(\"**********************************\")\n",
    "    print(\"Episode: {}\".format(e + 1))\n",
    "    enviroment.render()\n",
    "    print(\"**********************************\")\n",
    "    print(\"reward is :\")\n",
    "    y = reward\n",
    "    print(reward)\n",
    "    xList.append(e+1)\n",
    "    yList.append(y)\n",
    "    drawnow(makeFig)\n",
    "agent.q_network.summary()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}